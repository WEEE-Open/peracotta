# P.E.R.A.C.O.T.T.A.

*Progetto Esteso Raccolta Automatica Configurazioni hardware Organizzate Tramite Tarallo Autonomamente*

Script to gather hardware data and update [T.A.R.A.L.L.O.](weee-open/tarallo) automatically.

## How to run

Clone this repo:  
`git clone https://github.com/weee-open/peracotta`  
Make a virtual environment in the directory of the repo:  
`cd peracotta`    
`python3 -m venv venv`  
Activate it:  
`source venv/bin/activate`  
Install the requirements in the virtual environment:  
`pip install -r requirements.txt`  
Use it.  
When you're done, exit the virtualenv with `deactivate` 
or simply close the terminal you were using.

For developers, if requirements change:  
- install the correct version of the requirements (e.g. a new library or a new version of an already installed library)  
- with the virtual environment activated, run `pip freeze > requirements.txt`  

## generate_files.sh

This will create some txt files with data related to the computer, that will be parsed by launching 
`extract_data.py`. The hard work is powered by the many `read_X.py` scripts, which are the actual 
parsers.

Install dependencies on Debian-based distributions (Debian, Ubuntu, Xubuntu, etc):  
`sudo apt install pciutils i2c-tools mesa-utils smartmontools dmidecode`  
These are the actual programs that generate the files that we parse.

## extract_data.py

You can pass as the path argument the directory where generate_files.sh dropped its files. By default (i.e. if you don't give any arguments 
to `generate_files.sh`) it will output the files in the current directory. Since this may clutter the working directory 
with txt files, it's best to make a new directory (e.g. `mkdir tmp`) and pass it to the file generator (e.g. `generate_files.sh tmp`).
You can then pass this path to this script so that it knows where to find the txt files (e.g. `./extract_data.py -g tmp`).  
This is done automatically by the GUI version.  
  
You can find the usage below, but keep in mind that the two most important arguments are:
- the path to the txt files (if none given, it will default to the current directory)
- `-g | -c | -b`: one of these is required to tell the script where the GPU (or graphics card if it's not integrated) is located

```
usage: extract_data.py [-h] (-g | -c | -b) [-s | -l | -i] [-v] [path]

Parse the files generated with generate_files.sh and get all the possible info
out of them

positional arguments:
  path               path to directory with txt files generated by
                     generate_files.sh - defaults to current directory

optional arguments:
  -h, --help         show this help message and exit
  -v, --verbose      print some warning messages

GPU Location (one argument required):
  -g, --gpu          computer has dedicated GPU
  -c, --cpu          GPU is integrated inside the CPU
  -b, --motherboard  GPU is integrated inside the motherboard

With or without GUI (one argument optional):
  -s, --short        enabled by default, this is the option you want if you
                     want to copy-paste this output into the TARALLO 'Bulk
                     Add' page
  -l, --long         print longer output
  -i, --gui          launch GUI instead of using the terminal version
```

## main_with_gui.py

Launch it, there's a GUI. It looks cool.  
The GUI is also available from `extract_data.py` with the `-i` or `--gui` option.

## read_X.py

There are many read_something.py scripts: these are used internally by the other scripts. They can also be launched from the command line. They can also be imported as libraries.
